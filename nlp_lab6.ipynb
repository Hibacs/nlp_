{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDnaumKP8NON"
      },
      "source": [
        "# Text Preprocessing Exercise\n",
        "##### Author: Alex Sherman | alsherman@deloitte.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O92CZLkd8NOP"
      },
      "source": [
        "#### Agenda\n",
        "\n",
        "1. SpaCy\n",
        "2. Text Tokenization, POS Tagging, Parsing, NER\n",
        "3. Text Pipelines\n",
        "4. Phrase Models\n",
        "5. Python Fundamentals: Collections, Itertools, list comprehensions, sorted, apply\n",
        "6. Text Rule-based matching\n",
        "7. Advanced SpaCy Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "7fpPEtkb_qC_",
        "outputId": "c6057de5-0a1a-4067-bab8-100a9cf8f8fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_lg==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.0.0/en_core_web_lg-2.0.0.tar.gz#egg=en_core_web_lg==2.0.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.0.0/en_core_web_lg-2.0.0.tar.gz (852.3MB)\n",
            "\u001b[K     |████████████████████████████████| 852.3MB 1.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wfjbg37g/wheels/0d/bc/67/e6a9108ab86cd076703af19ad4e0f02f57381ac6583df16249\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.0.0\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_lg -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en_core_web_lg\n",
            "\n",
            "    You can now load the model via spacy.load('en_core_web_lg')\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# INSTALLATION\n",
        "!python -m spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "s7_Qsl5S8NOQ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/f8/kw10cxwn3fq163bpb2n465mm0000gn/T/ipykernel_3661/2746644729.py:3: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
            "  from IPython.core.display import display, HTML\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from IPython.core.display import display, HTML\n",
        "from IPython.display import Image\n",
        "from configparser import ConfigParser, ExtendedInterpolation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Xorg1WkY-LNa"
      },
      "outputs": [],
      "source": [
        "f = r'https://raw.githubusercontent.com/Alexjmsherman/nlp_practicum_cohort3_instructor/master/raw_data/pubmed/pubmed_data.txt?token=ABXRUPVQ4HTKOPTZQN3PE7K47JPWW'\n",
        "df = pd.read_csv(f, sep='\\t', header=None, names=['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "IUxPXpqn8NOn",
        "outputId": "00f167f2-12b3-4d8b-9373-5fe08a0cc7f3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>acid base diagrams</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>immunising against receptors for antigen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>immune complexes in rheumatic disease</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>loss of hla antigens associated with hormonal state</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hypocalcaemia after thyroidectomy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text\n",
              "0                                   acid base diagrams\n",
              "1             immunising against receptors for antigen\n",
              "2                immune complexes in rheumatic disease\n",
              "3  loss of hla antigens associated with hormonal state\n",
              "4                    hypocalcaemia after thyroidectomy"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# increase the number of characters displayed in each column\n",
        "pd.set_option('display.max_colwidth', 100)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>495529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>chem</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>159</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          text\n",
              "count   500000\n",
              "unique  495529\n",
              "top       chem\n",
              "freq       159"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "R8zJ-3g78NOo",
        "outputId": "89fdeadf-d671-4eab-a66e-c0d03bf75c9d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'to investigate the myelinotoxicity of cerebropsinal fluid in multiple sclerosis we used an in vivo model of the myelinated central nervous system tract of tadpoles for quantitative double blind tests of cerebrospinal fluid samples'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# example text\n",
        "text = df.text[27]\n",
        "text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcqqJuZ08NOr"
      },
      "source": [
        "### SpaCy\n",
        "\n",
        "\"SpaCy is a free, open-source library for advanced Natural Language Processing (NLP) in Python.\n",
        "\n",
        "If you're working with a lot of text, you'll eventually want to know more about it. For example, what's it about? What do the words mean in context? Who is doing what to whom? What companies and products are mentioned? Which texts are similar to each other?\n",
        "\n",
        "SpaCy is designed specifically for production use and helps you build applications that process and \"understand\" large volumes of text. It can be used to build information extraction or natural language understanding systems, or to pre-process text for deep learning.\n",
        "\n",
        "SpaCy is not research software. It's built on the latest research, but it's designed to get things done. This leads to fairly different design decisions than NLTK or CoreNLP, which were created as platforms for teaching and research. The main difference is that SpaCy is integrated and opinionated. SpaCy tries to avoid asking the user to choose between multiple algorithms that deliver equivalent functionality. Keeping the menu small lets SpaCy deliver generally better performance and developer experience.\"\n",
        "\n",
        "### SpaCy Features\n",
        "\n",
        "NAME |\tDESCRIPTION |\n",
        ":----- |:------|\n",
        "Tokenization|Segmenting text into words, punctuations marks etc.|\n",
        "Part-of-speech (POS) Tagging|Assigning word types to tokens, like verb or noun.|\n",
        "Dependency Parsing|\tAssigning syntactic dependency labels, describing the relations between individual tokens, like subject or object.|\n",
        "Lemmatization|\tAssigning the base forms of words. For example, the lemma of \"was\" is \"be\", and the lemma of \"rats\" is \"rat\".|\n",
        "Sentence Boundary Detection (SBD)|\tFinding and segmenting individual sentences.|\n",
        "Named Entity Recognition (NER)|\tLabelling named \"real-world\" objects, like persons, companies or locations.|\n",
        "Similarity|\tComparing words, text spans and documents and how similar they are to each other.|\n",
        "Text Classification|\tAssigning categories or labels to a whole document, or parts of a document.|\n",
        "Rule-based Matching|\tFinding sequences of tokens based on their texts and linguistic annotations, similar to regular expressions.|\n",
        "Training|\tUpdating and improving a statistical model's predictions.|\n",
        "Serialization|\tSaving objects to files or byte strings.|\n",
        "\n",
        "SOURCE: https://spacy.io/usage/spacy-101"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "4ugggJ6R8NOw",
        "outputId": "e16bbe6f-2d3b-42cd-9b6a-3a57006a02cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/usr/bin/python3'"
            ]
          },
          "execution_count": 6,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# confirm which conda environment you are using - make sure it is one with SpaCy installed\n",
        "import sys\n",
        "sys.executable\n",
        "\n",
        "# if you have difficulty importing spacy try the following in git bash\n",
        "# conda install ipykernel --name Python3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6Ki0yyaw8NOz"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy import displacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "gTvyDGgg8NO3",
        "outputId": "23d7284f-4128-475e-e471-6dfac1680d66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 636 ms, sys: 76.8 ms, total: 712 ms\n",
            "Wall time: 713 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# read in a simple (small) English language model\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "# another approach:\n",
        "# import en_core_web_sm\n",
        "# nlp = en_core_web_sm.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "nbi36eZy8NO6",
        "outputId": "3f504717-5237-4858-d865-eaa3936ecd04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 11.6 s, sys: 1.35 s, total: 12.9 s\n",
            "Wall time: 12.9 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# read in a (large) convolutional neural network model\n",
        "# this will only work after the CNN model is downloaded (~800MB)\n",
        "# e.g. python -m spacy download en_core_web_lg\n",
        "nlp = spacy.load('en_core_web_lg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "oAHUGUGy8NO9",
        "outputId": "b9e0d7e5-cc76-4461-fe01-f53e22926b2f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'to investigate the myelinotoxicity of cerebropsinal fluid in multiple sclerosis we used an in vivo model of the myelinated central nervous system tract of tadpoles for quantitative double blind tests of cerebrospinal fluid samples'"
            ]
          },
          "execution_count": 12,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# review text\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7EVFx-18NPA"
      },
      "outputs": [],
      "source": [
        "# instantiate the document text\n",
        "doc = nlp(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "egZWUXVc8NPC",
        "outputId": "88f62821-b992-4970-b2e4-b6c1762b0abd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "to investigate the myelinotoxicity of cerebropsinal fluid in multiple sclerosis we used an in vivo model of the myelinated central nervous system tract of tadpoles for quantitative double blind tests of cerebrospinal fluid samples"
            ]
          },
          "execution_count": 14,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# view the text from the SpaCy object\n",
        "doc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "lWqeMoxP8NPG",
        "outputId": "9f4cc594-f89e-408e-a796-d82bd9e5af95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['_', '__bytes__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__pyx_vtable__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__unicode__', '_bulk_merge', '_py_tokens', '_realloc', '_vector', '_vector_norm', 'cats', 'char_span', 'count_by', 'doc', 'ents', 'extend_tensor', 'from_array', 'from_bytes', 'from_disk', 'get_extension', 'get_lca_matrix', 'has_extension', 'has_vector', 'is_parsed', 'is_sentenced', 'is_tagged', 'mem', 'merge', 'noun_chunks', 'noun_chunks_iterator', 'print_tree', 'remove_extension', 'retokenize', 'sentiment', 'sents', 'set_extension', 'similarity', 'tensor', 'text', 'text_with_ws', 'to_array', 'to_bytes', 'to_disk', 'user_data', 'user_hooks', 'user_span_hooks', 'user_token_hooks', 'vector', 'vector_norm', 'vocab']\n"
          ]
        }
      ],
      "source": [
        "# which the SpaCy document methods and attributes\n",
        "print(dir(doc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YagTh_208NPI"
      },
      "source": [
        "### NLP Pipeline\n",
        "\n",
        "When you read the text into spaCy, e.g. doc = nlp(text), you are applying a pipeline of nlp processes to the text.\n",
        "by default spaCy applies a tagger, parser, and ner, but you can choose to add, replace, or remove these steps.\n",
        "Note: Removing unnecessary steps for a given nlp can lead to substantial descreses in processing time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "GIdVNj458NPJ",
        "outputId": "4afab7fd-b2a3-42e2-bce0-3dbfe1ecb2e9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<iframe src=https://spacy.io/images/pipeline.svg width=1000 height=200></iframe>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# SpaCy pipeline\n",
        "spacy_url = 'https://spacy.io/images/pipeline.svg'\n",
        "iframe = '<iframe src={} width=1000 height=200></iframe>'.format(spacy_url)\n",
        "HTML(iframe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-Dcaq3N8NPM"
      },
      "source": [
        "## Tokenization\n",
        "\n",
        "SpaCy first tokenizes the text, i.e. segments it into words, punctuation and so on. This is done by applying rules specific to each language. For example, punctuation at the end of a sentence should be split off – whereas \"U.K.\" should remain one token."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***************************  Exercise 1  ***************************\n",
        "\n",
        "Count the number of word tokens in the text columns of the dataframe loaded `df`? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_tokens_using_spacy(text):\n",
        "    count = 0\n",
        "    # ---- complete code here --- #\n",
        "    \n",
        "    return count\n",
        "\n",
        "count_tokens_using_spacy(df.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxcLVrtY8NPS"
      },
      "source": [
        "##### Lexeme - entries in the vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "DYAbmlqw8NPV",
        "outputId": "69c5901d-f68a-4752-8893-8cb30b0e113f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example stop words: ['another', 'few', 'others', 'rather', 'using', 'serious', 'so', 'an', 'anything', 'around']\n"
          ]
        }
      ],
      "source": [
        "# import a list of stop words from SpaCy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "\n",
        "print('Example stop words: {}'.format(list(STOP_WORDS)[0:10]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "kKwBb0wH8NPY",
        "outputId": "0272b921-2521-44b6-d9fc-6993038a513d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<spacy.lexeme.Lexeme at 0x7f0e2fae6558>"
            ]
          },
          "execution_count": 21,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nlp.vocab['have']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "G2kdOLvi8NPa",
        "outputId": "3d11a19d-3718-43e6-fe20-13984f3b938b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__pyx_vtable__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', 'check_flag', 'cluster', 'flags', 'from_bytes', 'has_vector', 'is_alpha', 'is_ascii', 'is_bracket', 'is_currency', 'is_digit', 'is_left_punct', 'is_lower', 'is_oov', 'is_punct', 'is_quote', 'is_right_punct', 'is_space', 'is_stop', 'is_title', 'is_upper', 'lang', 'lang_', 'like_email', 'like_num', 'like_url', 'lower', 'lower_', 'norm', 'norm_', 'orth', 'orth_', 'prefix', 'prefix_', 'prob', 'rank', 'sentiment', 'set_attrs', 'set_flag', 'shape', 'shape_', 'similarity', 'suffix', 'suffix_', 'text', 'to_bytes', 'vector', 'vector_norm', 'vocab']\n"
          ]
        }
      ],
      "source": [
        "print(dir(nlp.vocab['have']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "-ur_6WSs8NPe",
        "outputId": "ecbbb3c4-40cd-46b3-c84f-5e015a503bdb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 23,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nlp.vocab['have'].is_stop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJ1opBWw8NPi"
      },
      "outputs": [],
      "source": [
        "# search for word in the SpaCy vocabulary and\n",
        "# change the is_stop attribute to True\n",
        "\n",
        "for word in STOP_WORDS:\n",
        "    nlp.vocab[word].is_stop = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Krp5V-1u8NPm"
      },
      "source": [
        "### Part-of-speech (POS) Tagging\n",
        "\n",
        "After tokenization, spaCy can parse and tag a given Doc. This is where the statistical model comes in, which enables spaCy to make a prediction of which tag or label most likely applies in this context. A model consists of binary data and is produced by showing a system enough examples for it to make predictions that generalize across the language – for example, a word following \"the\" in English is most likely a noun.\n",
        "\n",
        "Annotation | Description\n",
        ":----- |:------|\n",
        "Text |The original word text|\n",
        "Lemma |The base form of the word.|\n",
        "POS |The simple part-of-speech tag.|\n",
        "Tag |The detailed part-of-speech tag.|\n",
        "Dep |Syntactic dependency, i.e. the relation between tokens.|\n",
        "Shape |The word shape – capitalisation, punctuation, digits.|\n",
        "Is Alpha |Is the token an alpha character?|\n",
        "Is Stop |Is the token part of a stop list, i.e. the most common words of the language?|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "leScZeKn8NPn",
        "outputId": "9b78b404-4c5c-43a1-e7d5-74bb961b2b01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "to investigate the myelinotoxicity of cerebropsinal fluid in multiple sclerosis we used an in vivo model of the myelinated central nervous system tract of tadpoles for quantitative double blind tests of cerebrospinal fluid samples"
            ]
          },
          "execution_count": 25,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# review document\n",
        "doc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "AIua107P8NPo",
        "outputId": "0bdd4217-bf2d-43b9-cd9f-8fcbbdd73c52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 26,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check if POS tags were added to the doc in the NLP pipeline\n",
        "doc.is_tagged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        },
        "id": "cmUmchxI8NPq",
        "outputId": "17c3d069-d97f-4680-fa01-c98525558b80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TEXT            | LEMMA_          | POS_     | TAG_     | DEP_        | SHAPE_   | IS_ALPHA | IS_STOP  | \n",
            "to              | to              | PART     | TO       | aux         | xx       |        1 |        1 |\n",
            "investigate     | investigate     | VERB     | VB       | ROOT        | xxxx     |        1 |        0 |\n",
            "the             | the             | DET      | DT       | det         | xxx      |        1 |        1 |\n",
            "myelinotoxicity | myelinotoxicity | NOUN     | NN       | dobj        | xxxx     |        1 |        0 |\n",
            "of              | of              | ADP      | IN       | prep        | xx       |        1 |        1 |\n",
            "cerebropsinal   | cerebropsinal   | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
            "fluid           | fluid           | NOUN     | NN       | pobj        | xxxx     |        1 |        0 |\n",
            "in              | in              | ADP      | IN       | prep        | xx       |        1 |        1 |\n",
            "multiple        | multiple        | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
            "sclerosis       | sclerosis       | NOUN     | NN       | pobj        | xxxx     |        1 |        0 |\n",
            "we              | -PRON-          | PRON     | PRP      | nsubj       | xx       |        1 |        1 |\n",
            "used            | use             | VERB     | VBD      | relcl       | xxxx     |        1 |        1 |\n",
            "an              | an              | DET      | DT       | det         | xx       |        1 |        1 |\n",
            "in              | in              | ADP      | IN       | dobj        | xx       |        1 |        1 |\n",
            "vivo            | vivo            | ADJ      | JJ       | compound    | xxxx     |        1 |        0 |\n",
            "model           | model           | NOUN     | NN       | pobj        | xxxx     |        1 |        0 |\n",
            "of              | of              | ADP      | IN       | prep        | xx       |        1 |        1 |\n",
            "the             | the             | DET      | DT       | det         | xxx      |        1 |        1 |\n",
            "myelinated      | myelinat        | VERB     | VBN      | amod        | xxxx     |        1 |        0 |\n",
            "central         | central         | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
            "nervous         | nervous         | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
            "system          | system          | NOUN     | NN       | compound    | xxxx     |        1 |        0 |\n",
            "tract           | tract           | NOUN     | NN       | pobj        | xxxx     |        1 |        0 |\n",
            "of              | of              | ADP      | IN       | prep        | xx       |        1 |        1 |\n",
            "tadpoles        | tadpole         | NOUN     | NNS      | pobj        | xxxx     |        1 |        0 |\n",
            "for             | for             | ADP      | IN       | prep        | xxx      |        1 |        1 |\n",
            "quantitative    | quantitative    | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
            "double          | double          | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
            "blind           | blind           | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
            "tests           | test            | NOUN     | NNS      | pobj        | xxxx     |        1 |        0 |\n",
            "of              | of              | ADP      | IN       | prep        | xx       |        1 |        1 |\n",
            "cerebrospinal   | cerebrospinal   | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
            "fluid           | fluid           | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
            "samples         | sample          | NOUN     | NNS      | pobj        | xxxx     |        1 |        0 |\n"
          ]
        }
      ],
      "source": [
        "# print column headers\n",
        "print('{:15} | {:15} | {:8} | {:8} | {:11} | {:8} | {:8} | {:8} | '.format(\n",
        "    'TEXT','LEMMA_','POS_','TAG_','DEP_','SHAPE_','IS_ALPHA','IS_STOP'))\n",
        "\n",
        "# print various SpaCy POS attributes\n",
        "for token in doc:\n",
        "    print('{:15} | {:15} | {:8} | {:8} | {:11} | {:8} | {:8} | {:8} |'.format(\n",
        "          token.text, token.lemma_, token.pos_, token.tag_, token.dep_\n",
        "        , token.shape_, token.is_alpha, token.is_stop))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfBunf228NPu"
      },
      "source": [
        "##### *************************** Exercise 2 ***************************\n",
        "\n",
        "Search and create (adjective_noun) phrases using parts of speech tags\n",
        "\n",
        "For example, in the sentence `\"I like delicious food\"` you need to extract and return `delicious_food` as phrase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "p7AeibBq8NPv",
        "outputId": "4e6cf737-f099-47c0-dae0-23195a491f95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cerebropsinal_fluid\n",
            "multiple_sclerosis\n",
            "vivo_model\n",
            "nervous_system\n",
            "blind_tests\n",
            "fluid_samples\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def find_adj_nn_phrases_from_text(text):\n",
        "    # ---- complete code here --- #\n",
        "\n",
        "    \n",
        "find_adj_nn_phrases_from_text(text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFghS9z-8NPy"
      },
      "source": [
        "##### word sense disambiguation via part of speech tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "e4EMDYlT8NPz",
        "outputId": "02321cd4-2d06-4939-d56e-3478ff67065d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "to_PART\n",
            "investigate_VERB\n",
            "the_DET\n",
            "myelinotoxicity_NOUN\n",
            "of_ADP\n",
            "cerebropsinal_ADJ\n",
            "fluid_NOUN\n",
            "in_ADP\n",
            "multiple_ADJ\n",
            "sclerosis_NOUN\n",
            "we_PRON\n",
            "used_VERB\n",
            "an_DET\n",
            "in_ADP\n",
            "vivo_ADJ\n",
            "model_NOUN\n",
            "of_ADP\n",
            "the_DET\n",
            "myelinated_VERB\n",
            "central_ADJ\n"
          ]
        }
      ],
      "source": [
        "for token in doc[0:20]:\n",
        "    print(f'{token.text}_{token.pos_}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjeRFnyn8NP4"
      },
      "source": [
        "### Text Dependency Parsing\n",
        "\n",
        "spaCy features a fast and accurate syntactic dependency parser, and has a rich API for navigating the tree. The parser also powers the sentence boundary detection, and lets you iterate over base noun phrases, or \"chunks\". You can check whether a Doc  object has been parsed with the doc.is_parsed attribute, which returns a boolean value. If this attribute is False, the default sentence iterator will raise an exception."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "rETU0Rue8NP5",
        "outputId": "a37932db-6243-4f84-dbf4-072a9fcc45b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 30,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check is document has been parsed (dependency parsing)\n",
        "doc.is_parsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        },
        "id": "rtBUKvkA8NP7",
        "outputId": "0a0025c1-c7e1-48d0-d545-86a2e1ad92ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TEXT            | DEP        | HEAD TEXT       | HEAD POS   | CHILDREN                  | LEFTS                    \n",
            "to              | aux        | investigate     | VERB       | []                        | []                       \n",
            "investigate     | ROOT       | investigate     | VERB       | [to, myelinotoxicity]     | ['to']                   \n",
            "the             | det        | myelinotoxicity | NOUN       | []                        | []                       \n",
            "myelinotoxicity | dobj       | investigate     | VERB       | [the, of, in, used]       | ['the']                  \n",
            "of              | prep       | myelinotoxicity | NOUN       | [fluid]                   | []                       \n",
            "cerebropsinal   | amod       | fluid           | NOUN       | []                        | []                       \n",
            "fluid           | pobj       | of              | ADP        | [cerebropsinal]           | ['cerebropsinal']        \n",
            "in              | prep       | myelinotoxicity | NOUN       | [sclerosis]               | []                       \n",
            "multiple        | amod       | sclerosis       | NOUN       | []                        | []                       \n",
            "sclerosis       | pobj       | in              | ADP        | [multiple]                | ['multiple']             \n",
            "we              | nsubj      | used            | VERB       | []                        | []                       \n",
            "used            | relcl      | myelinotoxicity | NOUN       | [we, in, for]             | ['we']                   \n",
            "an              | det        | in              | ADP        | []                        | []                       \n",
            "in              | dobj       | used            | VERB       | [an, model]               | ['an']                   \n",
            "vivo            | compound   | model           | NOUN       | []                        | []                       \n",
            "model           | pobj       | in              | ADP        | [vivo, of]                | ['vivo']                 \n",
            "of              | prep       | model           | NOUN       | [tract]                   | []                       \n",
            "the             | det        | tract           | NOUN       | []                        | []                       \n",
            "myelinated      | amod       | tract           | NOUN       | []                        | []                       \n",
            "central         | amod       | tract           | NOUN       | []                        | []                       \n",
            "nervous         | amod       | system          | NOUN       | []                        | []                       \n",
            "system          | compound   | tract           | NOUN       | [nervous]                 | ['nervous']              \n",
            "tract           | pobj       | of              | ADP        | [the, myelinated, central, system, of] | ['the', 'myelinated', 'central', 'system']\n",
            "of              | prep       | tract           | NOUN       | [tadpoles]                | []                       \n",
            "tadpoles        | pobj       | of              | ADP        | []                        | []                       \n",
            "for             | prep       | used            | VERB       | [tests]                   | []                       \n",
            "quantitative    | amod       | tests           | NOUN       | []                        | []                       \n",
            "double          | amod       | tests           | NOUN       | []                        | []                       \n",
            "blind           | amod       | tests           | NOUN       | []                        | []                       \n",
            "tests           | pobj       | for             | ADP        | [quantitative, double, blind, of] | ['quantitative', 'double', 'blind']\n",
            "of              | prep       | tests           | NOUN       | [samples]                 | []                       \n",
            "cerebrospinal   | amod       | samples         | NOUN       | []                        | []                       \n",
            "fluid           | amod       | samples         | NOUN       | []                        | []                       \n",
            "samples         | pobj       | of              | ADP        | [cerebrospinal, fluid]    | ['cerebrospinal', 'fluid']\n"
          ]
        }
      ],
      "source": [
        "print('{:15} | {:10} | {:15} | {:10} | {:25} | {:25}'.format(\n",
        "    'TEXT','DEP','HEAD TEXT','HEAD POS','CHILDREN','LEFTS'))\n",
        "\n",
        "for token in doc:\n",
        "    print('{:15} | {:10} | {:15} | {:10} | {:25} | {:25}'.format(\n",
        "        token.text, token.dep_, token.head.text, token.head.pos_,\n",
        "        str([child for child in token.children]), str([t.text for t in token.lefts])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LoPi89B8NP-"
      },
      "source": [
        "#### NOUN CHUNCKS:\n",
        "\n",
        "| **TERM** | Definition |\n",
        "|:---|:---:|\n",
        "| **Text** | The original noun chunk text |\n",
        "| **Root text** | The original text of the word connecting the noun chunk to the rest of the parse |\n",
        "| **Root dependency** | Dependency relation connecting the root to its head |\n",
        "| **Root head text** | The text of the root token's head |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "id": "snqyl7jx8NP_",
        "outputId": "f1c8523c-2d2b-4498-c416-cfec6140d52f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROOT_TEXT       | ROOT       | DEPENDENCY      | TEXT                                    \n",
            "myelinotoxicity | dobj       | investigate     | the myelinotoxicity                     \n",
            "fluid           | pobj       | of              | cerebropsinal fluid                     \n",
            "sclerosis       | pobj       | in              | multiple sclerosis                      \n",
            "we              | nsubj      | used            | we                                      \n",
            "model           | pobj       | in              | vivo model                              \n",
            "tract           | pobj       | of              | the myelinated central nervous system tract\n",
            "tadpoles        | pobj       | of              | tadpoles                                \n",
            "tests           | pobj       | for             | quantitative double blind tests         \n",
            "samples         | pobj       | of              | cerebrospinal fluid samples             \n"
          ]
        }
      ],
      "source": [
        "print('{:15} | {:10} | {:15} | {:40}'.format('ROOT_TEXT','ROOT','DEPENDENCY','TEXT'))\n",
        "\n",
        "for chunk in list(doc.noun_chunks):\n",
        "    print('{:15} | {:10} | {:15} | {:40}'.format(\n",
        "        chunk.root.text, chunk.root.dep_, chunk.root.head.text, chunk.text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 878
        },
        "id": "ah2DqQVE8NQE",
        "outputId": "d58f220b-378a-443c-b830-1a31a230450d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"864-0\" class=\"displacy\" width=\"6000\" height=\"837.0\" style=\"max-width: none; height: 837.0px; color: #000000; background: #ffffff; font-family: Arial\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">to</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PART</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">investigate</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">myelinotoxicity</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">of</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">cerebropsinal</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">fluid</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">in</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">multiple</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">sclerosis</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">we</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">used</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">an</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">in</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">vivo</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">model</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">of</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">myelinated</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3375\">central</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3375\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3550\">nervous</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3550\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3725\">system</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3725\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3900\">tract</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3900\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4075\">of</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4075\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4250\">tadpoles</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4250\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4425\">for</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4425\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4600\">quantitative</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4600\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4775\">double</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4775\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4950\">blind</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4950\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5125\">tests</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5125\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5300\">of</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5300\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5475\">cerebrospinal</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5475\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5650\">fluid</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5650\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5825\">samples</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5825\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-0\" stroke-width=\"2px\" d=\"M70,702.0 C70,614.5 190.0,614.5 190.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,704.0 L62,692.0 78,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-1\" stroke-width=\"2px\" d=\"M420,702.0 C420,614.5 540.0,614.5 540.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M420,704.0 L412,692.0 428,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-2\" stroke-width=\"2px\" d=\"M245,702.0 C245,527.0 545.0,527.0 545.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M545.0,704.0 L553.0,692.0 537.0,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-3\" stroke-width=\"2px\" d=\"M595,702.0 C595,614.5 715.0,614.5 715.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M715.0,704.0 L723.0,692.0 707.0,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-4\" stroke-width=\"2px\" d=\"M945,702.0 C945,614.5 1065.0,614.5 1065.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M945,704.0 L937,692.0 953,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-5\" stroke-width=\"2px\" d=\"M770,702.0 C770,527.0 1070.0,527.0 1070.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-5\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1070.0,704.0 L1078.0,692.0 1062.0,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-6\" stroke-width=\"2px\" d=\"M595,702.0 C595,352.0 1255.0,352.0 1255.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-6\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1255.0,704.0 L1263.0,692.0 1247.0,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-7\" stroke-width=\"2px\" d=\"M1470,702.0 C1470,614.5 1590.0,614.5 1590.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-7\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1470,704.0 L1462,692.0 1478,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-8\" stroke-width=\"2px\" d=\"M1295,702.0 C1295,527.0 1595.0,527.0 1595.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-8\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1595.0,704.0 L1603.0,692.0 1587.0,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-9\" stroke-width=\"2px\" d=\"M1820,702.0 C1820,614.5 1940.0,614.5 1940.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-9\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1820,704.0 L1812,692.0 1828,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-10\" stroke-width=\"2px\" d=\"M595,702.0 C595,89.5 1970.0,89.5 1970.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-10\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">relcl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1970.0,704.0 L1978.0,692.0 1962.0,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-11\" stroke-width=\"2px\" d=\"M2170,702.0 C2170,614.5 2290.0,614.5 2290.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-11\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2170,704.0 L2162,692.0 2178,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-12\" stroke-width=\"2px\" d=\"M1995,702.0 C1995,527.0 2295.0,527.0 2295.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-12\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2295.0,704.0 L2303.0,692.0 2287.0,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-13\" stroke-width=\"2px\" d=\"M2520,702.0 C2520,614.5 2640.0,614.5 2640.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-13\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2520,704.0 L2512,692.0 2528,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-14\" stroke-width=\"2px\" d=\"M2345,702.0 C2345,527.0 2645.0,527.0 2645.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-14\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2645.0,704.0 L2653.0,692.0 2637.0,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-15\" stroke-width=\"2px\" d=\"M2695,702.0 C2695,614.5 2815.0,614.5 2815.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-15\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2815.0,704.0 L2823.0,692.0 2807.0,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-16\" stroke-width=\"2px\" d=\"M3045,702.0 C3045,264.5 3885.0,264.5 3885.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-16\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3045,704.0 L3037,692.0 3053,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-17\" stroke-width=\"2px\" d=\"M3220,702.0 C3220,352.0 3880.0,352.0 3880.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-17\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3220,704.0 L3212,692.0 3228,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-18\" stroke-width=\"2px\" d=\"M3395,702.0 C3395,439.5 3875.0,439.5 3875.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-18\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3395,704.0 L3387,692.0 3403,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-19\" stroke-width=\"2px\" d=\"M3570,702.0 C3570,614.5 3690.0,614.5 3690.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-19\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3570,704.0 L3562,692.0 3578,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-20\" stroke-width=\"2px\" d=\"M3745,702.0 C3745,614.5 3865.0,614.5 3865.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-20\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3745,704.0 L3737,692.0 3753,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-21\" stroke-width=\"2px\" d=\"M2870,702.0 C2870,177.0 3890.0,177.0 3890.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-21\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3890.0,704.0 L3898.0,692.0 3882.0,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-22\" stroke-width=\"2px\" d=\"M3920,702.0 C3920,614.5 4040.0,614.5 4040.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-22\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4040.0,704.0 L4048.0,692.0 4032.0,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-23\" stroke-width=\"2px\" d=\"M4095,702.0 C4095,614.5 4215.0,614.5 4215.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-23\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4215.0,704.0 L4223.0,692.0 4207.0,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-24\" stroke-width=\"2px\" d=\"M1995,702.0 C1995,2.0 4425.0,2.0 4425.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-24\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4425.0,704.0 L4433.0,692.0 4417.0,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-25\" stroke-width=\"2px\" d=\"M4620,702.0 C4620,439.5 5100.0,439.5 5100.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-25\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4620,704.0 L4612,692.0 4628,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-26\" stroke-width=\"2px\" d=\"M4795,702.0 C4795,527.0 5095.0,527.0 5095.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-26\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4795,704.0 L4787,692.0 4803,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-27\" stroke-width=\"2px\" d=\"M4970,702.0 C4970,614.5 5090.0,614.5 5090.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-27\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4970,704.0 L4962,692.0 4978,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-28\" stroke-width=\"2px\" d=\"M4445,702.0 C4445,352.0 5105.0,352.0 5105.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-28\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5105.0,704.0 L5113.0,692.0 5097.0,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-29\" stroke-width=\"2px\" d=\"M5145,702.0 C5145,614.5 5265.0,614.5 5265.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-29\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5265.0,704.0 L5273.0,692.0 5257.0,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-30\" stroke-width=\"2px\" d=\"M5495,702.0 C5495,527.0 5795.0,527.0 5795.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-30\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5495,704.0 L5487,692.0 5503,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-31\" stroke-width=\"2px\" d=\"M5670,702.0 C5670,614.5 5790.0,614.5 5790.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-31\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5670,704.0 L5662,692.0 5678,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-864-0-32\" stroke-width=\"2px\" d=\"M5320,702.0 C5320,439.5 5800.0,439.5 5800.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-864-0-32\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5800.0,704.0 L5808.0,692.0 5792.0,692.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# dependency visualization\n",
        "\n",
        "# show visualization in Jupyter Notebook\n",
        "displacy.render(docs=doc, style='dep', jupyter=True)\n",
        "\n",
        "# Another Option\n",
        "# uncomment and run the below code, then open another browser tab and go to http://localhost:5000\n",
        "# when you are done (before you run the next cell in the notebook) stop this cell\n",
        "# displacy.serve(docs=doc, style='dep')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "####  *************************** Exercise 3 ***************************\n",
        "\n",
        "Using spacy dependency parser, find subjects and direct objects for all the verbs in given text. \n",
        "\n",
        "Print the the results as triples (SUBJ, VERB, OBJ)  \n",
        "\n",
        "Perform your experiments on the dataframe text column\n",
        "\n",
        "Check the results, do you get full correct phrases for SUBJ and OBJ? Why? How can you improve the output?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_subj_verb_obj(text):\n",
        "# ---- complete code here --- #\n",
        "\n",
        "find_subj_verb_obj(df.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRcs2Pwe8NQJ"
      },
      "source": [
        "### Named Entity Recognition (NER)\n",
        "\n",
        "A named entity is a \"real-world object\" that's assigned a name – for example, a person, a country, a product, or a book title. spaCy can recognise various types of named entities in a document, by asking the model for a prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZX-nWlv8NQK"
      },
      "outputs": [],
      "source": [
        "ner_text = \"When I told John that I wanted to move to Alaska, he warned me that I'd have trouble finding a Starbucks there.\"\n",
        "ner_doc = nlp(ner_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "qvh-5WHG8NQN",
        "outputId": "e2e196cb-7a95-44a7-dea4-fc83fea1b784"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LABEL      | ENTITY         \n",
            "PERSON     | John                                              \n",
            "GPE        | Alaska                                            \n",
            "ORG        | Starbucks                                         \n"
          ]
        }
      ],
      "source": [
        "print('{:10} | {:15}'.format('LABEL','ENTITY'))\n",
        "\n",
        "for ent in ner_doc.ents[0:20]:\n",
        "    print('{:10} | {:50}'.format(ent.label_, ent.text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "2n4DR_rG8NQP",
        "outputId": "aa980463-d3c2-4644-ba64-9b7d4f51b7b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['_', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__pyx_vtable__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '_recalculate_indices', '_vector', '_vector_norm', 'as_doc', 'doc', 'end', 'end_char', 'ent_id', 'ent_id_', 'ents', 'get_extension', 'get_lca_matrix', 'has_extension', 'has_vector', 'label', 'label_', 'lefts', 'lemma_', 'lower_', 'merge', 'n_lefts', 'n_rights', 'noun_chunks', 'orth_', 'remove_extension', 'rights', 'root', 'sent', 'sentiment', 'set_extension', 'similarity', 'start', 'start_char', 'string', 'subtree', 'text', 'text_with_ws', 'to_array', 'upper_', 'vector', 'vector_norm', 'vocab']\n"
          ]
        }
      ],
      "source": [
        "# ent methods and attributes\n",
        "print(dir(ent))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "Aw3J9f148NQS",
        "outputId": "309f37cf-f9f8-449b-83a5-ee3cdaa3e2ec"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div class=\"entities\" style=\"line-height: 2.5\">When I told \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
              "    John\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " that I wanted to move to \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
              "    Alaska\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ", he warned me that I'd have trouble finding a \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
              "    Starbucks\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " there.</div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# entity visualization\n",
        "# after you run this code, open another browser and go to http://localhost:5000\n",
        "# when you are done (before you run the next cell in the notebook) stop this cell\n",
        "\n",
        "displacy.render(docs=ner_doc, style='ent', jupyter=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8xiK8L18NQU"
      },
      "source": [
        "# Pipeline\n",
        "\n",
        "If you have a sequence of documents to process, you should use the Language.pipe()  method. The method takes an iterator of texts, and accumulates an internal buffer, which it works on in parallel. It then yields the documents in order, one-by-one.\n",
        "\n",
        "- batch_size: number of docs to process per thread\n",
        "- disable: Names of pipeline components to disable to speed up text processing.\n",
        "                                    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8z1HosO8NQV"
      },
      "outputs": [],
      "source": [
        "from spacy.pipeline import Pipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "xfmnzxJd8NQY",
        "outputId": "db02b44f-8b83-40c6-dda9-3520712e61b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lines with the term immune: 3531\n",
            "\n",
            "immune complexes in rheumatic disease \n",
            "\n",
            "the human reovirus like hrvl agent nebraska calf diarrhea virus ncdv epizootic diarrhea of infant mice edim virus simian agent sa and the offal agent were found to be similar if not identical in reciprocal complement fixation cf tests employing hyperimmune animal sera \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# create a dataframe with a subset of the data, mentioning the word immune\n",
        "immune_df = df[df.text.str.contains('immune')].text\n",
        "\n",
        "# print the count of matches\n",
        "print('Lines with the term immune: {}\\n'.format(len(immune_df)))\n",
        "\n",
        "# view the first five section names\n",
        "for line in immune_df.head(2):\n",
        "    print(line, '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "itX-zT1v8NQb",
        "outputId": "2ef4e2d7-c343-4468-8532-731b80c84d23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "immune complexes in rheumatic disease \n",
            "\n",
            "the human reovirus like hrvl agent nebraska calf diarrhea virus ncdv epizootic diarrhea of infant mice edim virus simian agent sa and the offal agent were found to be similar if not identical in reciprocal complement fixation cf tests employing hyperimmune animal sera \n",
            "\n",
            "the immunoglobulin ig of rabbit anti vaccinia serum and the ig of the pre immune serum conjugated with fluorescein isothiocyanate fitc was employed \n",
            "\n",
            "evidence of an underlying immune mechanism was sought \n",
            "\n",
            "cultured allografts can be rejected if the host immune system is stimulated with viable leukocytes of donor origin \n",
            "\n",
            "we used the loose body test after van soeren as screening test controlled positive test results for several times under the same experimental conditions and supplemented it by the le cell test after zinkham and conley or later on by the immune fluorescence test \n",
            "\n",
            "membrane antigens of cultured human melanoma line uclaso were studied using immune adherence techniques \n",
            "\n",
            "fine specificity of the linked immune response gene for the gallinaceous lysozymes \n",
            "\n",
            "an immune response ir gene is described which controls the ability of mice to respond to seven very closely related gallinaceous egg white lysozymes gel \n",
            "\n",
            "immune response to of the epitope specific antibody \n",
            "\n",
            "CPU times: user 137 ms, sys: 73.2 ms, total: 210 ms\n",
            "Wall time: 134 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "for doc in nlp.pipe(immune_df.head(10)):  # includes ['parser','tagger','ner']\n",
        "    if 'immune' in doc.text:\n",
        "        print(doc, '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GscwhizG8NQj"
      },
      "source": [
        "### SpaCy - Tips for faster processing\n",
        "\n",
        "You can substantially speed up the time it takes SpaCy to read a document by disabling components of the NLP that are not necessary for a given task.\n",
        "\n",
        "- Disable options: **parser, tagger, ner**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "FJ8-YpHO8NQk",
        "outputId": "480ee5a5-7d8a-4e82-c9fb-3fa18dd95e7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "immune complexes in rheumatic disease \n",
            "\n",
            "the human reovirus like hrvl agent nebraska calf diarrhea virus ncdv epizootic diarrhea of infant mice edim virus simian agent sa and the offal agent were found to be similar if not identical in reciprocal complement fixation cf tests employing hyperimmune animal sera \n",
            "\n",
            "the immunoglobulin ig of rabbit anti vaccinia serum and the ig of the pre immune serum conjugated with fluorescein isothiocyanate fitc was employed \n",
            "\n",
            "evidence of an underlying immune mechanism was sought \n",
            "\n",
            "cultured allografts can be rejected if the host immune system is stimulated with viable leukocytes of donor origin \n",
            "\n",
            "we used the loose body test after van soeren as screening test controlled positive test results for several times under the same experimental conditions and supplemented it by the le cell test after zinkham and conley or later on by the immune fluorescence test \n",
            "\n",
            "membrane antigens of cultured human melanoma line uclaso were studied using immune adherence techniques \n",
            "\n",
            "fine specificity of the linked immune response gene for the gallinaceous lysozymes \n",
            "\n",
            "an immune response ir gene is described which controls the ability of mice to respond to seven very closely related gallinaceous egg white lysozymes gel \n",
            "\n",
            "immune response to of the epitope specific antibody \n",
            "\n",
            "CPU times: user 9.57 ms, sys: 919 µs, total: 10.5 ms\n",
            "Wall time: 10.6 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# processing occurs ~75x faster by disabling pipeline components\n",
        "for doc in nlp.pipe(immune_df.head(10), disable=['parser','tagger','ner']):\n",
        "    if 'immune' in doc.text:\n",
        "        print(doc, '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJc6HDHh8NQn"
      },
      "source": [
        "##### Determine which NLP components can be disabled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlOd9NRZ8NQo"
      },
      "outputs": [],
      "source": [
        "def view_pos(doc, n_tokens=5):\n",
        "    \"\"\" print SpaCy POS information about each token in a provided document \"\"\"\n",
        "    print('{:15} | {:10} | {:10} | {:30}'.format('TOKEN','POS','DEP_','LEFTS'))\n",
        "    for token in doc[0:n_tokens]:\n",
        "        print('{:15} | {:10} | {:10} | {:30}'.format(\n",
        "            token.text, token.head.pos_,token.dep_, str([t.text for t in token.lefts])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "IXpR8M478NQt",
        "outputId": "a684aff0-e6d3-4a47-fb3f-5bdca5f17753"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TOKEN           | POS        | DEP_       | LEFTS                         \n",
            "to              | VERB       | aux        | []                            \n",
            "investigate     | VERB       | ROOT       | ['to']                        \n",
            "the             | NOUN       | det        | []                            \n",
            "myelinotoxicity | VERB       | dobj       | ['the']                       \n",
            "of              | NOUN       | prep       | []                            \n"
          ]
        }
      ],
      "source": [
        "# observe results from the default pipeline\n",
        "pos_doc = nlp(text)\n",
        "view_pos(pos_doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "_td-r8tw8NQx",
        "outputId": "b4500a42-9a1a-4faf-d6e1-fc2aee9904fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TOKEN           | POS        | DEP_       | LEFTS                         \n",
            "to              | PART       |            | []                            \n",
            "investigate     | VERB       |            | []                            \n",
            "the             | DET        |            | []                            \n",
            "myelinotoxicity | NOUN       |            | []                            \n",
            "of              | ADP        |            | []                            \n"
          ]
        }
      ],
      "source": [
        "# observe which part of speech (pos) attributes are disabled by parser\n",
        "pos_doc = nlp(text, disable=['ner','parser'])\n",
        "view_pos(pos_doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "4lwIBUTE8NQ1",
        "outputId": "7e08be84-df49-4f15-e8fd-8c1ccc3f4f4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TOKEN           | POS        | DEP_       | LEFTS                         \n",
            "to              |            | aux        | []                            \n",
            "investigate     |            | ROOT       | ['to']                        \n",
            "the             |            | det        | []                            \n",
            "myelinotoxicity |            | dobj       | ['the']                       \n",
            "of              |            | prep       | []                            \n"
          ]
        }
      ],
      "source": [
        "# observe which part of speech (pos) attributes are disabled by tagger\n",
        "pos_doc = nlp(text, disable=['ner','tagger'])\n",
        "view_pos(pos_doc, n_tokens=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op6O-v0b8NQ3"
      },
      "source": [
        "### Fast Sentence Boundary Detection (SBD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "veiPmSFs8NQ4",
        "outputId": "94f87340-6d1d-454d-d963-86dbe056d353"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is a sentence.\n",
            "This is another sentence.\n"
          ]
        }
      ],
      "source": [
        "from spacy.lang.en import English\n",
        "\n",
        "nlp_sbd = English()  # just the language with no model\n",
        "\n",
        "sentencizer = nlp.create_pipe(\"sentencizer\")\n",
        "nlp_sbd.add_pipe(sentencizer)\n",
        "doc = nlp_sbd(\"This is a sentence. This is another sentence.\")\n",
        "for sent in doc.sents:\n",
        "    print(sent.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4SftJqF8NQ7"
      },
      "source": [
        "### *************************** Exercise ***************************\n",
        "1. print all the distinct entities tagged with 'CARDINAL'\n",
        "2. print all the distinct entities tagged with 'PERSON'\n",
        "3. print all the distinct entities tagged with 'GPE'\n",
        "\n",
        "For all exercises:\n",
        "- use a batch size of 100\n",
        "- disable the parser and tagger (ner is needed to add the tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "cWrK79f98NQ8",
        "outputId": "ac937c09-632d-48c8-ae12-24c9265fb3b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 6.91 µs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# print all the distinct entities tagged as a CARDINAL\n",
        "# search in immune_df.head(200)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "M9QXcBNb8NQ-",
        "outputId": "ba4e152c-2dce-446b-d3bc-006e587d5878"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 6.44 µs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# print all the distinct entities tagged as an organization (ORG)\n",
        "# search in immune_df.head(500)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "bGvJNYxi8NRC",
        "outputId": "cc3a241e-4188-4718-b665-7d83db94fb0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 15 µs, sys: 3 µs, total: 18 µs\n",
            "Wall time: 21.7 µs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# print all the distinct entities tagged as a geopolitical entity (GPE)\n",
        "# search in immune_df.head(1000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8lKVVLl8NRF"
      },
      "source": [
        "### Collocations\n",
        "\n",
        "\"A collocation is an expression consisting of two or more words that\n",
        "correspond to some conventional way of saying things. Or in the words\n",
        "of Firth (1957: 181): “Collocations of a given word are statements of the\n",
        "habitual or customary places of that word.” Collocations include noun\n",
        "phrases like strong tea and weapons of mass destruction, phrasal verbs like\n",
        "to make up, and other stock phrases like the rich and powerful. Particularly\n",
        "interesting are the subtle and not-easily-explainable patterns of word usage\n",
        "that native speakers all know: why we say a stiff breeze but not a stiff wind\n",
        "(while either a strong breeze or a strong wind is okay), or why we speak of\n",
        "broad daylight (but not bright daylight or narrow darkness)\n",
        "\n",
        "\n",
        "\n",
        "There are actually different definitions of the notion of collocation. Some\n",
        "authors in the computational and statistical literature define a collocation\n",
        "as two or more consecutive words with a special behavior, for example\n",
        "Choueka (1988):\n",
        "[A collocation is defined as] a sequence of two or more consecutive\n",
        "words, that has characteristics of a syntactic and semantic\n",
        "unit, and whose exact and unambiguous meaning or connotation\n",
        "cannot be derived directly from the meaning or connotation of its\n",
        "components. In most linguistically oriented research, a phrase\n",
        "can be a collocation even if it is not consecutive (as in the example knock\n",
        ". . . door). The following criteria are typical of linguistic treatments of collocations:\n",
        "\n",
        "**Non-compositionality**: The meaning of a collocation is not a straightforward\n",
        "composition of the meanings of its parts. Either the meaning\n",
        "is completely different from the free combination (as in the case of idioms\n",
        "like kick the bucket) or there is a connotation or added element of\n",
        "meaning that cannot be predicted from the parts. For example, white\n",
        "wine, white hair and white woman all refer to slightly different colors, so\n",
        "we can regard them as collocations.\n",
        "\n",
        "**Non-substitutability**: We cannot substitute near-synonyms for the\n",
        "components of a colloction. For example, we can’t say yellow wine\n",
        "instead of white wine even though yellow is as good a description of the\n",
        "color of white wine as white is (it is kind of a yellowish white).\n",
        "\n",
        "**Non-modifiability**: Many collocations cannot be freely modified with\n",
        "additional lexical material or through grammatical transformations.\n",
        "This is especially true for frozen expressions like idioms. For example,\n",
        "we can’t modify frog in to get a frog in one’s throat into to get an ugly\n",
        "frog in one’s throat although usually nouns like frog can be modified by\n",
        "adjectives like ugly. Similarly, going from singular to plural can make\n",
        "an idiom ill-formed, for example in people as poor as church mice.\"\n",
        "\n",
        "SOURCE: https://nlp.stanford.edu/fsnlp/promo/colloc.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb_OfSOs8NRG"
      },
      "source": [
        "### Phrase (collocation) Detection\n",
        "\n",
        "Phrase modeling is another approach to learning combinations of tokens that together represent meaningful multi-word concepts. We can develop phrase models by looping over the the words in our reviews and looking for words that co-occur (i.e., appear one after another) together much more frequently than you would expect them to by random chance. The formula our phrase models will use to determine whether two tokens $A$ and $B$ constitute a phrase is:\n",
        "\n",
        "$$\\frac{count(A\\ B) - count_{min}}{count(A) * count(B)} > threshold$$\n",
        "\n",
        "- $count(A\\ B)$ is the number of times the tokens $A\\ B$ appear in the corpus in order\n",
        "- $count_{min}$ is a user-defined parameter to ensure that accepted phrases occur a minimum number of times\n",
        "- $count(A)$ is the number of times token $A$ appears in the corpus\n",
        "- $count(B)$ is the number of times token $B$ appears in the corpus\n",
        "- $threshold$ is a user-defined parameter to control how strong of a relationship between two tokens the model requires before accepting them as a phrase\n",
        "\n",
        "Once our phrase model has been trained on our corpus, we can apply it to new text. When our model encounters two tokens in new text that identifies as a phrase, it will merge the two into a single new token.\n",
        "\n",
        "Phrase modeling is superficially similar to named entity detection in that you would expect named entities to become phrases in the model (so new york would become new_york). But you would also expect multi-word expressions that represent common concepts, but aren't specifically named entities (such as happy hour) to also become phrases in the model.\n",
        "\n",
        "We turn to the indispensible gensim library to help us with phrase modeling — the Phrases class in particular.\n",
        "\n",
        "SOURCE:\n",
        "- https://github.com/skipgram/modern-nlp-in-python/blob/master/executable/Modern_NLP_in_Python.ipynb\n",
        "- https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uyo5Qe8_8NRH"
      },
      "source": [
        "##### Gensim API\n",
        "A more complex API, though it is faster and has better integration with other gensim components (e.g. Phraser)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRawfSPG8NRI"
      },
      "outputs": [],
      "source": [
        "from gensim.models.phrases import Phrases, Phraser\n",
        "from gensim.utils import simple_preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "bMezRcIB8NRM",
        "outputId": "10bddd57-3829-4577-ceea-6c29aaebca30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "immune complexes in rheumatic disease \n",
            "\n",
            "['immune', 'complexes', 'in', 'rheumatic', 'disease']\n"
          ]
        }
      ],
      "source": [
        "# use gensim simple_preprocess to preprocess text\n",
        "for text in immune_df:\n",
        "    print(text, '\\n')\n",
        "    print(simple_preprocess(text))\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "4jxh9rKP8NRP",
        "outputId": "fc0cb64b-cdf2-4349-c7fa-7b475c425ea7",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['immune', 'complexes', 'in', 'rheumatic', 'disease'], ['the', 'human', 'reovirus', 'like', 'hrvl', 'agent', 'nebraska', 'calf', 'diarrhea', 'virus', 'ncdv', 'epizootic', 'diarrhea', 'of', 'infant', 'mice', 'edim', 'virus', 'simian', 'agent', 'sa', 'and', 'the', 'offal', 'agent', 'were', 'found', 'to', 'be', 'similar', 'if', 'not', 'identical', 'in', 'reciprocal', 'complement', 'fixation', 'cf', 'tests', 'employing', 'hyperimmune', 'animal', 'sera'], ['the', 'immunoglobulin', 'ig', 'of', 'rabbit', 'anti', 'vaccinia', 'serum', 'and', 'the', 'ig', 'of', 'the', 'pre', 'immune', 'serum', 'conjugated', 'with', 'fluorescein', 'isothiocyanate', 'fitc', 'was', 'employed'], ['evidence', 'of', 'an', 'underlying', 'immune', 'mechanism', 'was', 'sought'], ['cultured', 'allografts', 'can', 'be', 'rejected', 'if', 'the', 'host', 'immune', 'system', 'is', 'stimulated', 'with', 'viable', 'leukocytes', 'of', 'donor', 'origin']]\n"
          ]
        }
      ],
      "source": [
        "gensim_text = [simple_preprocess(text) for text in immune_df]\n",
        "\n",
        "print(gensim_text[0:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFRLNIqC8NRR"
      },
      "outputs": [],
      "source": [
        "# create a list of stop words\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "common_terms = list(STOP_WORDS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ainjd48o8NRT"
      },
      "source": [
        "**common_terms:** optional list of “stop words” that won’t affect frequency count of expressions containing them.\n",
        "- The common_terms parameter add a way to give special treatment to common terms (aka stop words) such that their presence between two words won’t prevent bigram detection. It allows to detect expressions like “bank of america” or “eye of the beholder”."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "xVQc4xnl8NRU",
        "outputId": "a7b76d8e-d68e-42f1-ec05-0aa0ae8201e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<gensim.models.phrases.Phrases at 0x7f0e08dff208>"
            ]
          },
          "execution_count": 54,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "phrases = Phrases(\n",
        "      gensim_text\n",
        "    , common_terms=common_terms\n",
        "    , min_count=5\n",
        "    , threshold=5\n",
        "    , scoring='default'\n",
        ")\n",
        "\n",
        "phrases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR5PwB6R8NRZ"
      },
      "source": [
        "### Phrases Params\n",
        "\n",
        "- **scoring:** specifies how potential phrases are scored for comparison to the threshold setting. scoring can be set with either a string that refers to a built-in scoring function, or with a function with the expected parameter names. Two built-in scoring functions are available by setting scoring to a string:\n",
        "\n",
        "    - ‘default’: from “Efficient Estimaton of Word Representations in Vector Space” by Mikolov, et. al.:\n",
        "    \n",
        "$$\\frac{count(AB) - count_{min}}{count(A) * count(B)} * N > threshold$$\n",
        "    \n",
        "\n",
        "\n",
        "    - where N is the total vocabulary size.\n",
        "    - Thus, it is easier to exceed the threshold when the two words occur together often or when the two words are rare (i.e. small product)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "OUBdxeDj8NRb",
        "outputId": "01968dc0-3571-41be-efc1-28617c265279"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<gensim.models.phrases.Phraser at 0x7f0e0936b128>"
            ]
          },
          "execution_count": 55,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bigram = Phraser(phrases)\n",
        "\n",
        "bigram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p34GJ8RI8NRk"
      },
      "source": [
        "The phrases object still contains all the source text in memory. A gensim Phraser will remove this extra data to become smaller and somewhat faster than using the full Phrases model. To determine what data to remove, the Phraser ues the  results of the source model’s min_count, threshold, and scoring settings. (You can tamper with those & create a new Phraser to try other values.)\n",
        "\n",
        "SOURCE: https://radimrehurek.com/gensim/models/phrases.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbSAVdvu8NRl"
      },
      "outputs": [],
      "source": [
        "def print_phrases(phraser, text_stream, num_underscores=2):\n",
        "    \"\"\" identify phrases from a text stream by searching for terms that\n",
        "        are separated by underscores and include at least num_underscores\n",
        "    \"\"\"\n",
        "\n",
        "    phrases = []\n",
        "    for terms in phraser[text_stream]:\n",
        "        for term in terms:\n",
        "            if term.count('_') >= num_underscores:\n",
        "                phrases.append(term)\n",
        "    print(set(phrases))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "S2P-h0dd8NRo",
        "outputId": "42274964-f51e-46fd-e66c-c64eaab43ffb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'foot_and_mouth', 'presence_of_circulating', 'effective_in_preventing', 'patients_with_rheumatoid', 'cellular_and_humoral', 'vitro_and_in_vivo', 'igg_and_igm', 'play_an_important', 'humoral_and_cellular', 'patients_with_malignant', 'role_in_the_pathogenesis', 'consistent_with_the_hypothesis', 'primary_and_secondary'}\n"
          ]
        }
      ],
      "source": [
        "print_phrases(bigram, gensim_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsD0jfiQ8NRu"
      },
      "source": [
        "### Tri-gram phrase model\n",
        "\n",
        "We can place the text from the first phrase model into another Phrases object to create n-term phrase models. We can repear this process multiple times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "LiHSV2W68NRu",
        "outputId": "229172bd-695f-497c-9e9f-a3a44ebaaa09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'immune_response_against_two_epitopes', 'immune_system_of_mice', 'immune_complexes_in_schistosomiasis', 'stimulation_of_the_immune_system', 'depression_of_cell_mediated', 'immune_reactivity_of_syngeneic', 'helper_and_suppressor_cells', 'cell_mediated_immune_reactivity', 'measured_by_the_tube', 'immune_response_to_srbc', 'antibody_to_hepatitis_antigen', 'investigation_of_the_effects', 'guinea_pig_and_bovine', 'immune_response_of_cattle', 'immune_electron_microscopy_iem', 'immune_responses_to_varicella_zoster', 'inbred_strains_of_mice', 'studies_indicate_that_pbb', 'elimination_of_immune_complexes', 'transfer_of_spleen_cells', 'components_of_the_immune_response', 'circulating_immune_complexes_ic', 'protective_effect_of_polyi', 'development_of_cell_mediated', 'detection_of_circulating_immune', 'appear_to_be_involved', 'conditions_in_the_guinea_pig', 'judged_by_immune_electron', 'patients_with_graves_disease', 'impairment_of_the_immune_response', 'immune_response_ir_genes', 'involvement_in_immune_response', 'immune_response_to_influenza_virus', 'humoral_or_cell_mediated', 'spleen_cells_from_congenic', 'immune_response_was_observed', 'role_of_immune_complexes', 'immune_response_of_lewis_rats', 'electron_microscopy_immune_electron', 'ability_of_the_cells', 'cell_mediated_immune_responses', 'immune_response_to_aerobic', 'varicella_zoster_and_herpes', 'play_role_in_the_pathogenesis', 'cimetidine_and_the_immune_response', 'sensitive_than_the_complement_fixation', 'demonstrated_to_the_aerobic', 'expression_of_immune_response', 'immune_responses_by_feeding', 'pathogenesis_of_the_diseases', 'modulation_of_the_immune_response', 'patients_with_rheumatoid_arthritis', 'haemolytic_anaemia_and_murine', 'immune_complexes_in_rheumatoid_arthritis', 'antibody_titres_were_determined', 'immune_status_of_pregnant', 'memory_in_cell_mediated', 'immune_responses_to_central_nervous', 'pretreatment_of_the_animals', 'regulation_of_humoral_immune', 'results_in_autoimmune_disease', 'deposits_of_immune_complexes', 'immune_response_of_normal', 'ingestion_on_immune_response', 'cyclic_amp_has_regulatory', 'cirrhosis_an_immune_complex', 'patients_with_autoimmune_thyroiditis', 'protein_antigens_in_mice', 'assessment_of_the_immune', 'humoral_and_cell_mediated', 'detectable_in_radioimmune_precipitation', 'titrated_by_the_immune_adherence', 'antigens_in_guinea_pigs', 'virus_infected_target_cells', 'compatible_with_immune_complex', 'rh_isoimmunization_during_pregnancy', 'immune_responses_in_mice', 'epstein_barr_virus_infection', 'generation_of_effector_cells', 'regulating_the_immune_response', 'sheep_red_blood_cells', 'immune_response_in_vitro', 'herpes_simplex_virus_infection', 'immune_complexes_in_normal', 'immune_response_to_insulin', 'horses_to_equine_herpesvirus', 'form_of_immune_complexes', 'transmission_of_auto_immune', 'influence_the_in_vitro_and_in_vivo', 'impairment_of_cell_mediated', 'antibodies_to_hepatitis_virus', 'immune_response_in_nude_mice', 'nonimmune_and_immune_surveillance', 'immune_response_to_tumor', 'patients_with_systemic_lupus', 'tumor_cells_to_resist', 'lys_and_also_suppressed', 'capacity_of_spleen_cells', 'immune_responses_in_human', 'level_of_circulating_immune', 'patients_with_cytomegalovirus_infection', 'patients_with_malignant_disease', 'developed_an_immune_response', 'stimulation_of_the_in_vitro', 'evidence_of_immune_complex', 'cellular_and_humoral_immune_responses', 'immune_reactivity_in_patients', 'antibody_to_hepatitis_virus', 'appeared_during_the_acute', 'polymers_are_under_distinct', 'lead_to_an_understanding', 'observations_are_consistent_with_the_hypothesis', 'immune_complexes_are_present', 'sodium_dodecyl_sulfate_polyacrylamide', 'suppression_of_the_immune_response', 'effective_in_preventing_rh_isoimmunization', 'collagen_and_of_collagen', 'regulation_of_the_immune_response', 'immune_response_to_hapten', 'compatible_with_the_hypothesis', 'igg_and_igm_antibodies', 'immune_response_to_bluetongue', 'transformed_by_simian_virus', 'cellular_and_humoral_immune', 'immune_competence_with_age', 'immune_status_of_the_study', 'pathogenesis_of_rheumatoid_arthritis', 'immune_response_to_virus_infection', 'study_of_the_effect', 'cell_mediated_immune_status', 'responses_of_spleen_cells', 'organ_specific_autoimmune_disorders', 'immune_response_of_rats', 'ability_of_tumor_cells', 'patients_with_recurrent_herpes', 'immune_responses_in_swine', 'raji_cell_radioimmune_assay', 'found_by_immune_electron', 'parameters_of_the_immune_response', 'effect_of_alpha_fetoprotein', 'antibody_to_varicella_zoster', 'infected_with_herpes_simplex', 'function_in_the_mouse', 'cultured_in_the_presence', 'reduction_in_the_number', 'immune_response_to_neoplasia', 'foot_and_mouth_disease', 'suppression_of_the_primary', 'detection_of_immune_complexes', 'acute_phase_of_the_illness', 'differ_at_the_cellular', 'immune_response_to_herpes_simplex', 'immune_response_was_detected', 'phagocytosis_of_circulating_immune', 'specificity_of_cellular_immune', 'barrier_and_the_local', 'assay_was_used_to_measure', 'reaction_by_antigen_agent', 'suppression_of_humoral_immune', 'titre_against_the_nadl', 'immune_response_of_mice', 'appeared_to_be_associated', 'guinea_pig_myelin_basic', 'pathogenesis_of_the_disease', 'visualized_by_immune_electron', 'response_to_hepatitis_virus', 'phagocytosis_of_immune_complexes', 'participate_in_the_pathogenesis', 'fractionated_by_affinity_chromatography', 'hsv_infected_target_cells', 'cells_to_humoral_immune', 'role_in_the_regulation', 'rabbits_and_guinea_pigs', 'discussed_in_the_light', 'effects_of_alpha_fetoprotein', 'treatment_with_hyperimmune_serum', 'determine_the_immune_status', 'development_of_cellular_immune', 'cell_mediated_immune_response', 'immune_response_of_allophenic', 'antibody_and_cell_mediated', 'modification_of_the_immune_response', 'passive_transfer_of_contact', 'presence_of_an_antigen', 'course_of_the_disease', 'antibody_to_herpes_simplex', 'parameters_of_immune_responsiveness', 'specificity_and_cross_reactivity', 'induction_of_immune_response', 'detected_by_immune_electron', 'control_of_two_distinct', 'genetic_control_of_immune_responsiveness', 'peptide_of_guinea_pig', 'herpes_simplex_virus_infected', 'defined_in_balb_mice', 'immune_status_of_the_host', 'considered_to_be_of_practical', 'vitro_in_the_presence', 'induced_by_the_administration', 'immune_complexes_were_found', 'presence_of_immune_complexes', 'inhibition_of_the_hosts', 'regulate_the_immune_response', 'immune_response_to_sheep_erythrocytes', 'immune_responses_in_vitro', 'stages_of_the_disease', 'immune_response_of_chickens', 'patients_with_other_diseases', 'nature_of_the_immune_response', 'sulfate_polyacrylamide_gel_electrophoresis', 'suppress_the_immune_response', 'immune_complexes_in_the_circulation', 'immune_response_to_allogeneic', 'cell_carcinoma_of_the_lung', 'level_of_immune_complexes', 'role_in_the_pathogenesis', 'stage_of_the_disease', 'patients_with_malignant_melanoma', 'results_in_immune_system', 'plasma_exchange_was_followed', 'effect_on_the_induction', 'compared_to_the_saline', 'cell_mediated_immune_reactions', 'immune_response_was_obtained', 'studied_in_guinea_pigs', 'suppression_of_cell_mediated', 'antibody_to_the_norwalk', 'genetic_control_of_the_immune_response', 'play_an_important_role', 'significance_of_immune_responses', 'patients_with_multiple_sclerosis', 'impairment_of_the_immune_system', 'correlated_with_the_presence', 'immune_response_to_chemically', 'immune_response_in_chickens', 'immune_response_to_soluble', 'evidence_for_the_role', 'humoral_and_cellular_immune_response', 'organ_specific_autoimmune_diseases', 'immune_response_of_prostatic', 'detectable_by_immune_adherence', 'phase_of_the_immune_response', 'region_of_the_complex', 'spleen_and_lymph_nodes', 'modification_of_the_immune', 'igg_antibodies_from_erythrocytes', 'patients_with_other_autoimmune_disorders', 'spleen_cells_from_mice', 'immune_complexes_in_diabetic', 'radioimmune_assay_for_human', 'necessary_for_the_development', 'primary_and_secondary_immune_responses', 'receptors_for_immune_complexes', 'immune_adherence_and_complement_fixation', 'tumor_specific_immune_response', 'immune_response_in_calves', 'infection_with_herpes_simplex', 'aspects_of_immune_response', 'vivo_and_in_vitro', 'participation_of_immune_reactions', 'cell_mediated_and_humoral_immune', 'induction_of_antigen_specific', 'changes_in_circulating_immune', 'group_of_immune_response', 'immune_response_to_staphylococcal', 'cell_mediated_immune_system', 'obtained_from_patients_with_rheumatoid', 'consistent_with_the_hypothesis', 'cellular_and_humoral_immune_reactivity', 'deposition_of_immune_complexes', 'anti_foot_and_mouth', 'immune_complexes_in_ovarian', 'adherence_inhibition_lai_assay', 'systemic_humoral_and_cellular', 'targets_were_themselves_inactivated', 'data_are_consistent_with_the_hypothesis', 'gene_products_in_virus', 'manifestations_of_autoimmune_disease', 'measured_by_radioimmune_assay', 'evidence_of_circulating_immune', 'mouse_and_guinea_pig', 'occurrence_of_circulating_immune', 'presence_of_circulating_immune_complexes', 'inhibition_of_the_immune_response', 'patients_with_autoimmune_thyroid', 'immune_responsiveness_ir_genes', 'tests_of_immune_competence', 'syngeneic_sv_transformed_cells', 'studied_for_their_effects', 'immune_responses_in_patients', 'modulation_of_immune_responses', 'immune_response_to_cell_surface', 'spleen_cells_in_vitro', 'regulation_of_the_humoral_immune', 'experimental_autoimmune_myasthenia_gravis', 'tolerant_to_human_gamma', 'cases_with_autoimmune_thyroid', 'meeting_of_the_german', 'immune_response_to_tumors', 'immune_complexes_in_pregnancy', 'specificity_of_the_in_vitro', 'formation_of_immune_complexes', 'immune_response_of_pigs', 'levels_of_circulating_immune', 'levels_of_immune_complexes', 'clinical_and_immune_responses', 'remained_in_the_supernatant', 'role_of_the_immune_response', 'patients_with_malignant_glial', 'role_in_the_immune_response', 'immune_response_against_syngeneic_sv', 'characteristics_of_the_immune_response', 'antibodies_to_varicella_zoster', 'immune_response_are_discussed', 'evidence_for_an_ige', 'hepatitis_antigen_ha_ag', 'immune_complexes_were_detected', 'patients_with_down_syndrome', 'depression_of_immune_responses', 'evoke_an_immune_response', 'reactions_of_the_cell_population', 'microscopy_and_solid_phase', 'vitro_and_in_vivo', 'type_and_immune_interferon', 'immune_response_ir_gene', 'studies_on_the_immune_response', 'binding_of_immune_complexes', 'cancer_patients_to_cytomegalovirus', 'prove_to_be_useful', 'humoral_and_cellular_immune_responses', 'regulation_of_immune_responses', 'immune_responses_to_vaginal', 'fluorescent_antibody_to_membrane', 'immune_status_of_children'}\n"
          ]
        }
      ],
      "source": [
        "phrases = Phrases(\n",
        "      bigram[gensim_text]\n",
        "    , common_terms=common_terms\n",
        "    , min_count=1\n",
        "    , threshold=1\n",
        ")\n",
        "\n",
        "trigram = Phraser(phrases)\n",
        "\n",
        "print_phrases(trigram, bigram[gensim_text], num_underscores=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "id": "TZDrQv5t8NRy",
        "outputId": "6b089e6a-2d63-47ca-d8fc-73c2428aca8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DOC NUMBER: 0\n",
            "\n",
            "ORIGINAL SENTENT: immune complexes in rheumatic disease\n",
            "\n",
            "BIGRAM: immune_complexes in rheumatic disease\n",
            "\n",
            "TRIGRAM: immune_complexes in rheumatic disease\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for doc_num in [0]:\n",
        "    print('DOC NUMBER: {}\\n'.format(doc_num))\n",
        "    print('ORIGINAL SENTENT: {}\\n'.format(' '.join(gensim_text[doc_num])))\n",
        "    print('BIGRAM: {}\\n'.format(' '.join(bigram[gensim_text[doc_num]])))\n",
        "    print('TRIGRAM: {}'.format(' '.join(trigram[bigram[gensim_text[doc_num]]])))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSnG3Po18NR0"
      },
      "source": [
        "#### Export Cleaned Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHz1ItaU8NR1"
      },
      "outputs": [],
      "source": [
        "# write the cleaned text to a new file for later use\n",
        "\n",
        "#with open(CLEANED_TEXT_PATH, 'w') as f:\n",
        "#    for line in bigram[gensim_text]:\n",
        "#        line = ' '.join(line) + '\\n'\n",
        "#        line = line.encode('ascii', errors='ignore').decode('ascii')\n",
        "#        f.write(line)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGDnl3Oq8NR5"
      },
      "source": [
        "# Advanced Python\n",
        "\n",
        "A brief overview of some advanced Python which will be used in future lessons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtHDGIiU8NR5"
      },
      "source": [
        "##### Collections - DefaultDict\n",
        "\n",
        "Usually, a Python dictionary throws a KeyError if you try to get an item with a key that is not currently in the dictionary. The defaultdict in contrast will simply create any items that you try to access (provided of course they do not exist yet). To create such a \"default\" item, it calls the function object that you pass in the constructor (more precisely, it's an arbitrary \"callable\" object, which includes function and type objects). For the first example, default items are created using int(), which will return the integer object 0. For the second example, default items are created using list(), which returns a new empty list object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3GybN7t8NR6"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3gvaY5u8NR8"
      },
      "outputs": [],
      "source": [
        "pubmed_sentence = \"\"\"PubMed Description:\n",
        "PubMed comprises more than 28 million citations for biomedical literature from MEDLINE, life science journals, and online books.\n",
        "Citations may include links to full-text content from PubMed Central and publisher web sites.\"\"\".strip()\n",
        "\n",
        "example_doc = nlp(pubmed_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "RBqgDnoS8NR9",
        "outputId": "1bbe5d90-110f-426c-aedb-ab0283304e88"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-2dbcd6e6f289>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexample_doc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# cannot add if the key does not exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: PubMed"
          ]
        }
      ],
      "source": [
        "# WRONG APPROACH - KeyError!\n",
        "\n",
        "# try to create a word count dict with new keys\n",
        "d = {}\n",
        "for word in example_doc:\n",
        "    d[word] += 1  # cannot add if the key does not exist\n",
        "\n",
        "print(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "dyiwpys88NR_",
        "outputId": "52a06ddf-bb42-45c8-cf67-9d1cd92000ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "defaultdict(<class 'int'>, {'PubMed': 3, 'Description': 1, ':': 1, '\\n': 2, 'comprises': 1, 'more': 1, 'than': 1, '28': 1, 'million': 1, 'citations': 1, 'for': 1, 'biomedical': 1, 'literature': 1, 'from': 2, 'MEDLINE': 1, ',': 2, 'life': 1, 'science': 1, 'journals': 1, 'and': 2, 'online': 1, 'books': 1, '.': 2, 'Citations': 1, 'may': 1, 'include': 1, 'links': 1, 'to': 1, 'full': 1, '-': 1, 'text': 1, 'content': 1, 'Central': 1, 'publisher': 1, 'web': 1, 'sites': 1})\n"
          ]
        }
      ],
      "source": [
        "d = defaultdict(int)  # define the type of data the dict stores\n",
        "for word in example_doc:\n",
        "    d[word.text] += 1  # can add to unassigned keys\n",
        "\n",
        "print(d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl5JXsCS8NSB"
      },
      "source": [
        "##### Collections - Counter\n",
        "\n",
        "A Counter is a dict subclass for counting hashable objects. It is an unordered collection where elements are stored as dictionary keys and their counts are stored as dictionary values. Counts are allowed to be any integer value including zero or negative counts. The Counter class is similar to bags or multisets in other languages.\n",
        "\n",
        "SOURCE: https://docs.python.org/2/library/collections.html#collections.Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElEoHje08NSC"
      },
      "outputs": [],
      "source": [
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "i0skSbDa8NSG",
        "outputId": "3cd62ec7-9e3b-4557-8478-cd805b6e8c46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counter({'PubMed': 3, '\\n': 2, 'from': 2, ',': 2, 'and': 2, '.': 2, 'Description': 1, ':': 1, 'comprises': 1, 'more': 1, 'than': 1, '28': 1, 'million': 1, 'citations': 1, 'for': 1, 'biomedical': 1, 'literature': 1, 'MEDLINE': 1, 'life': 1, 'science': 1, 'journals': 1, 'online': 1, 'books': 1, 'Citations': 1, 'may': 1, 'include': 1, 'links': 1, 'to': 1, 'full': 1, '-': 1, 'text': 1, 'content': 1, 'Central': 1, 'publisher': 1, 'web': 1, 'sites': 1})\n"
          ]
        }
      ],
      "source": [
        "# count the number of times each CARDINAL appears\n",
        "print(Counter(d))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmQjQ5R18NSJ"
      },
      "source": [
        "##### Iterrtools - combinations\n",
        "\n",
        "\"The itertools module standardizes a core set of fast, memory efficient tools that are useful by themselves or in combination. Together, they form an “iterator algebra” making it possible to construct specialized tools succinctly and efficiently in pure Python.\n",
        "\n",
        "**Combinations**\n",
        "- Return r length subsequences of elements from the input iterable.\n",
        "- Combinations are emitted in lexicographic sort order. So, if the input iterable is sorted, the combination tuples will be produced in sorted order.\n",
        "- Elements are treated as unique based on their position, not on their value. So if the input elements are unique, there will be no repeat values in each combination.\n",
        "\n",
        "SOURCE: https://docs.python.org/3.4/library/itertools.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIH6stSX8NSK"
      },
      "outputs": [],
      "source": [
        "from itertools import combinations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "kedpP38-8NSN",
        "outputId": "75f9ac2f-5bf2-45ba-eed1-146913950df0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('PubMed', 'Medline')\n",
            "('PubMed', 'Citation')\n",
            "('PubMed', 'Biomedical')\n",
            "('Medline', 'Citation')\n",
            "('Medline', 'Biomedical')\n",
            "('Citation', 'Biomedical')\n"
          ]
        }
      ],
      "source": [
        "terms = ['PubMed','Medline','Citation','Biomedical']\n",
        "for combo in combinations(terms, 2):\n",
        "    print(combo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77ItoO7i8NSP"
      },
      "source": [
        "##### List Comprehensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "dZsh2do08NSP",
        "outputId": "28c1c3de-1574-44d4-bf87-873de0b0be18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['PubMed', 'Medline', 'Biomedical']"
            ]
          },
          "execution_count": 71,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# traditional iteration\n",
        "\n",
        "terms_subset = []\n",
        "for term in terms:\n",
        "    if 'med' in term.lower():\n",
        "        terms_subset.append(term)\n",
        "\n",
        "terms_subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "BH7vomy28NSR",
        "outputId": "3b36b1ca-7753-44bb-accd-a85a22eb9dd6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['PubMed', 'Medline', 'Biomedical']"
            ]
          },
          "execution_count": 72,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# list comprehension\n",
        "\n",
        "#   return value   iteration           conditional\n",
        "#[  term           for term in terms   if 'med' in term.lower()]\n",
        "\n",
        "[term for term in terms if 'med' in term.lower()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ8l3a9h8NST"
      },
      "source": [
        "##### Sorted\n",
        "\n",
        "sorted(iterable, key=None, reverse=False)\n",
        "\n",
        "- Return a new sorted list from the items in iterable.\n",
        "- Has two optional arguments which must be specified as keyword arguments.\n",
        "- key specifies a function of one argument that is used to extract a comparison key from each list element: key=str.lower. The default value is None (compare the elements directly).\n",
        "- reverse is a boolean value. If set to True, then the list elements are sorted as if each comparison were reversed.\n",
        "\n",
        "SOURCE: https://docs.python.org/3/library/functions.html#sorted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3m1xbiKR8NSW"
      },
      "outputs": [],
      "source": [
        "articles =[('article2', 3),('article3', 2),('article1', 1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "1HHRPDn18NSZ",
        "outputId": "0b740982-eb9d-41fb-e1f5-b68e8edfe722"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('article1', 1), ('article2', 3), ('article3', 2)]"
            ]
          },
          "execution_count": 74,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sorted(articles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "sYajzfGt8NSc",
        "outputId": "c6b9d2fe-6cc8-4d8f-d379-9aa81e572966"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('article1', 1), ('article3', 2), ('article2', 3)]"
            ]
          },
          "execution_count": 75,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sorted(articles, key=lambda x:x[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "sZKVRzPq8NSe",
        "outputId": "9e043475-634a-477a-972f-c5107a8fca7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('article2', 3), ('article3', 2), ('article1', 1)]"
            ]
          },
          "execution_count": 76,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sorted(articles, key=lambda x:x[1], reverse=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "1jd84GV28NSg",
        "outputId": "a7b49c03-edca-43a1-9376-986fb5a21c59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('article1', 1), ('article2', 3), ('article3', 2)]"
            ]
          },
          "execution_count": 77,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# sort based on the last character of the first term\n",
        "sorted(articles, key=lambda x:x[0][-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Srz799lK8NSh"
      },
      "source": [
        "##### Pandas Apply\n",
        "\n",
        "apply is an efficient and fast approach to 'apply' a function to every element in a row. applymap does the same to every element in the entire dataframe (e.g. convert all ints to floats)\n",
        "\n",
        "Example: https://chrisalbon.com/python/data_wrangling/pandas_apply_operations_to_dataframes/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "zStx9GaD8NSi",
        "outputId": "2dcfebd1-2e93-4a28-903a-726fcc3c3c1f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>col1</th>\n",
              "      <th>col2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   col1  col2\n",
              "0     0     3\n",
              "1     1     4\n",
              "2     2     5"
            ]
          },
          "execution_count": 78,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create a small dataframe with example data\n",
        "example_data = {'col1':range(0,3),'col2':range(3,6)}\n",
        "test_df = pd.DataFrame(example_data)\n",
        "test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "PlOFUymO8NSj",
        "outputId": "ce98c4d3-a09a-4181-ec64-a6a9374b3db4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    0.0\n",
              "1    1.0\n",
              "2    2.0\n",
              "Name: col1, dtype: float64"
            ]
          },
          "execution_count": 79,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# apply a built-in function to each element in a column\n",
        "test_df['col1'].apply(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "J-WZ9obZ8NSl",
        "outputId": "427d67ca-8ecd-450b-e18f-6d147a994697"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    5\n",
              "1    6\n",
              "2    7\n",
              "Name: col1, dtype: int64"
            ]
          },
          "execution_count": 80,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# apply a custom function to every element in a column\n",
        "def add_five(row):\n",
        "    return row + 5\n",
        "\n",
        "test_df['col1'].apply(add_five)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "UupxLBhX8NSn",
        "outputId": "4a56d602-4465-42e0-f655-a8bdf6633138"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    5\n",
              "1    6\n",
              "2    7\n",
              "Name: col1, dtype: int64"
            ]
          },
          "execution_count": 81,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# apply an annonomous function to every element in a column\n",
        "test_df['col1'].apply(lambda x: x+5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "rJH9xZ3q8NSu",
        "outputId": "f70ec620-3d6c-4a8b-bdec-e97caaad543d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>col1</th>\n",
              "      <th>col2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   col1  col2\n",
              "0   0.0   3.0\n",
              "1   1.0   4.0\n",
              "2   2.0   5.0"
            ]
          },
          "execution_count": 82,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# apply a built-in function to every element in a dataframe\n",
        "test_df.applymap(float)  # applymap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "2jWh55fD8NSy",
        "outputId": "884c4ce5-0745-41c2-9d99-8a0959d3f63d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>immune complexes in rheumatic disease</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>gluten and lymphocytes in coeliac disease</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>thalassaemic diseases and acute post streptococcal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>this activity correlated best with the severity and duration of the disease rather than with gam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>activity was negative in per cent of cerebrospinal fluid samples from control group with other n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                   text\n",
              "2                                                                 immune complexes in rheumatic disease\n",
              "6                                                             gluten and lymphocytes in coeliac disease\n",
              "9                                                    thalassaemic diseases and acute post streptococcal\n",
              "31  this activity correlated best with the severity and duration of the disease rather than with gam...\n",
              "32  activity was negative in per cent of cerebrospinal fluid samples from control group with other n..."
            ]
          },
          "execution_count": 83,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create a dataframe to on which to apply a function\n",
        "disease_df = df[df.text.str.contains('disease')].copy()\n",
        "disease_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiK0_MoQ8NS2"
      },
      "outputs": [],
      "source": [
        "# define a function to apply to the dataframe\n",
        "def noun_count(text):\n",
        "    \"\"\" count the number of nouns in the provided text\n",
        "\n",
        "    :param text: input text\n",
        "    :return num_nouns: number of nouns in the text\n",
        "    \"\"\"\n",
        "\n",
        "    num_nouns = 0\n",
        "    doc = nlp(text, disable=['ner'])\n",
        "\n",
        "    for token in doc:\n",
        "        if token.pos_ == 'NOUN':\n",
        "            num_nouns += 1\n",
        "\n",
        "    return num_nouns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "bdVAlx6r8NS3",
        "outputId": "d09f290b-a394-4327-a6bb-cca259c3114c"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-4258a6d2cb0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n# apply the function to the dataframe to create a new columns\\nimmune_df['noun_count'] = immune_df.text.apply(noun_count)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5065\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5066\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5067\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5069\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'text'"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# apply the function to the dataframe to create a new columns\n",
        "immune_df['noun_count'] = immune_df.text.apply(noun_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IOnc7kAl8NS6",
        "outputId": "35303244-121e-412d-e633-ca19117e4047"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2                                                                     immune complexes in rheumatic disease\n",
              "100     the human reovirus like hrvl agent nebraska calf diarrhea virus ncdv epizootic diarrhea of infan...\n",
              "217     the immunoglobulin ig of rabbit anti vaccinia serum and the ig of the pre immune serum conjugate...\n",
              "234                                                   evidence of an underlying immune mechanism was sought\n",
              "260     cultured allografts can be rejected if the host immune system is stimulated with viable leukocyt...\n",
              "337     we used the loose body test after van soeren as screening test controlled positive test results ...\n",
              "1102    membrane antigens of cultured human melanoma line uclaso were studied using immune adherence tec...\n",
              "1396                     fine specificity of the linked immune response gene for the gallinaceous lysozymes\n",
              "1397    an immune response ir gene is described which controls the ability of mice to respond to seven v...\n",
              "1404                                                    immune response to of the epitope specific antibody\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 86,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "immune_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21zmDMVK8NS8"
      },
      "source": [
        "### Exercise\n",
        "1. Count how many time each individual entity appears\n",
        "2. Create a mapping that keeps track of every combination of entities pairs that appear in the same sentence\n",
        "3. Count how many times each entity combo appears\n",
        "4. Print the entity combos (using sorted) in descending order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "k8pafru78NS9",
        "outputId": "ec9005b2-d9c6-44f1-c2c9-a0cf7f683739"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<unknown>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    entity_relations =\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# create a defaultdict(int) called entity_relations\n",
        "entity_relations =\n",
        "\n",
        "# create an empty list called counter_entities\n",
        "counter_entities =\n",
        "\n",
        "# during testing set .head() to a smaller number such as .head(1000)\n",
        "for doc in nlp.pipe(immune_df.head(1000), disable=['parser','tagger', 'ner']):\n",
        "\n",
        "    # store the token.text for all the tokens containing the letters 'toxic' (i.e. 'toxic' in term)\n",
        "    # use a list comprehension\n",
        "    entities =\n",
        "\n",
        "    # add the tokens from the current doc to counter_entities (use += to add the token.text)\n",
        "    counter_entities\n",
        "\n",
        "    # create combinations of two terms each time multiple 'toxic' words appear\n",
        "    # increment the count in entity_relations defaultdict each time a combo is repeated\n",
        "    for combo in combinations(entities, 2):\n",
        "        entity_relations[combo] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "NbBpY7Gi8NTA",
        "outputId": "e7c2f9a0-7672-4c4c-952e-a906afdf1e81"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-2107b3a3cae0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter_entities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'counter_entities' is not defined"
          ]
        }
      ],
      "source": [
        "print(Counter(counter_entities))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "VsuGbHVe8NTA",
        "outputId": "d4d083ad-d057-47ec-c946-f7e181c77cd7"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-6e04ed13e8e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity_relations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'entity_relations' is not defined"
          ]
        }
      ],
      "source": [
        "# view the entity pairs in descending order\n",
        "sorted(entity_relations.items(), key=lambda x: x[1], reverse=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "RJMH_DVG8NTB"
      },
      "source": [
        "### Identify Relevant Text (Rule-based Matching)\n",
        "\n",
        "Finding sequences of tokens based on their texts and linguistic annotations, similar to regular expressions. We will use this to filter and extract relevant text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "id": "xUFoQ6dg8NTB",
        "outputId": "1841e422-c745-49eb-8c85-586bd4ca2cb3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<iframe src=https://spacy.io/usage/linguistic-features#rule-based-matching width=1000 height=700></iframe>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 90,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rule_basesd_matching_url = 'https://spacy.io/usage/linguistic-features#rule-based-matching'\n",
        "iframe = '<iframe src={} width=1000 height=700></iframe>'.format(rule_basesd_matching_url)\n",
        "HTML(iframe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpa5up_38NTE"
      },
      "outputs": [],
      "source": [
        "# The Matcher identifies text from rules we specify\n",
        "from spacy.matcher import Matcher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEscqxY-8NTF"
      },
      "outputs": [],
      "source": [
        "# create a function to specify what to do with the matching text\n",
        "\n",
        "def collect_sents(matcher, doc, i, matches):\n",
        "    \"\"\"  collect and transform matching text\n",
        "\n",
        "    :param matcher: Matcher object\n",
        "    :param doc: is the full document to search for text patterns\n",
        "    :param i: is the index of the text matches\n",
        "    :param matches: matches found in the text\n",
        "    \"\"\"\n",
        "\n",
        "    match_id, start, end = matches[i]  # indices of matched term\n",
        "    span = doc[start:end]              # extract matched term\n",
        "\n",
        "    print('span: {} | start_ind:{:5} | end_ind:{:5} | id:{}'.format(\n",
        "        span, start, end, match_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "6jfyeeBd8NTJ",
        "outputId": "ff1152c8-1fbd-41e2-c548-59dcbdb2b00f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "span: disease | start_ind:    4 | end_ind:    5 | id:5781322434961390358\n",
            "span: disease | start_ind:   26 | end_ind:   27 | id:5781322434961390358\n",
            "span: disease | start_ind:   10 | end_ind:   11 | id:5781322434961390358\n",
            "span: disease | start_ind:   10 | end_ind:   11 | id:5781322434961390358\n",
            "span: disease | start_ind:   15 | end_ind:   16 | id:5781322434961390358\n",
            "CPU times: user 12.8 ms, sys: 3.36 ms, total: 16.2 ms\n",
            "Wall time: 19.4 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# set a pattern of text to collect\n",
        "# find all mentions of the word\n",
        "pattern = [{'LOWER':'disease'}] # LOWER coverts words to lowercase before matching\n",
        "\n",
        "# instantiate matcher\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# add pattern to the matcher (one matcher can look for many unique patterns)\n",
        "# provice a pattern name, function to apply to matches, pattern to identify\n",
        "matcher.add('disease', collect_sents, pattern)\n",
        "\n",
        "# pass the doc to the matcher to run the collect_sents function\n",
        "for doc in nlp.pipe(immune_df.head(100), disable=['parser','tagger','ner']):\n",
        "    matcher(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "VngTSlt38NTL",
        "outputId": "7fff6722-f61d-4787-ff12-dd2d0d3158de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SPAN: addison disease\n",
            "SENT: addison\n",
            "\n",
            "SPAN: analogy graves disease\n",
            "SENT: analogy\n",
            "\n",
            "SPAN: graves disease\n",
            "SENT: graves\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# change the function to print the sentence of the matched term (span)\n",
        "\n",
        "def collect_sents(matcher, doc, i, matches):\n",
        "    match_id, start, end = matches[i]\n",
        "    span = doc[start:end]\n",
        "    print('SPAN: {}'.format(span))\n",
        "\n",
        "    # span.sent provides the sentence that contains the span\n",
        "    print('SENT: {}'.format(span.sent))\n",
        "    print()\n",
        "\n",
        "\n",
        "# update the pattern to look for any noun preceeding the term 'fees'\n",
        "pattern = [{'POS': 'NOUN', 'OP': '+'},{'LOWER':'disease'}]\n",
        "matcher = Matcher(nlp.vocab)  # reinstantiate the matcher to remove previous patterns\n",
        "matcher.add('disease', collect_sents, pattern)\n",
        "\n",
        "for doc in nlp.pipe(immune_df.head(100), disable=['parser','ner']): # enable pos tagger\n",
        "    matcher(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTfGNHZN8NTN"
      },
      "outputs": [],
      "source": [
        "# change the function to collect sentences\n",
        "\n",
        "def collect_sents(matcher, doc, i, matches):\n",
        "    match_id, start, end = matches[i]\n",
        "    span = doc[start:end]\n",
        "\n",
        "    # update matched data collections\n",
        "    matched_sents.append(span.sent)\n",
        "\n",
        "\n",
        "matched_sents = []  # container for sentences\n",
        "pattern = [{'POS': 'NOUN', 'OP': '+'},{'LOWER':'disease'}]\n",
        "matcher = Matcher(nlp.vocab)\n",
        "matcher.add('disease', collect_sents, pattern)\n",
        "\n",
        "for doc in nlp.pipe(immune_df.head(100), disable=['ner']): # enable parser to collect sents\n",
        "    matcher(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "0-W2qd5x8NTR",
        "outputId": "f3524821-7dec-44f2-a1c8-2d8eb509dec9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{autoimmune thyreoiditis is controlled by the mhs in mice and chickens and in analogy graves disease is associated with hla in man,\n",
              " this may include several simultaneous autoimmune disorders such as addison disease thyroiditis pernicious anaemia and ovarian failure often combined with moniliasis and alopecia}"
            ]
          },
          "execution_count": 103,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# review matches\n",
        "set(matched_sents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "dsHnfCI68NTT",
        "outputId": "0ba6a2ed-a2cb-4edf-af09-4ddefb11052c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "defaultdict(int, {'disease': 5})"
            ]
          },
          "execution_count": 104,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# change the function to count matches using defaultdict\n",
        "\n",
        "def collect_sents(matcher, doc, i, matches):\n",
        "    match_id, start, end = matches[i]\n",
        "    span = doc[start:end]\n",
        "\n",
        "    # update matched data collections\n",
        "    ent_count[span.text] += 1  # defaultdict keys must use span.text not span!\n",
        "\n",
        "\n",
        "ent_count = defaultdict(int)\n",
        "pattern = [{'LOWER':'disease'}]\n",
        "matcher = Matcher(nlp.vocab)\n",
        "matcher.add('disease', collect_sents, pattern)\n",
        "\n",
        "for doc in nlp.pipe(immune_df.head(100), disable=['pos','ner']): # enable parser to collect sents\n",
        "    matcher(doc)\n",
        "\n",
        "ent_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "caDwjdmF8NTX",
        "outputId": "6a7419a7-499f-41ca-a9a8-7280d38b210b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 8.27 s, sys: 2.94 s, total: 11.2 s\n",
            "Wall time: 5.85 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# update the pattern to look for a noun describing the term\n",
        "\n",
        "ent_count = defaultdict(int)\n",
        "\n",
        "# change OP to 1 to only get a single term to the left\n",
        "pattern = [{'POS': 'NOUN', 'OP': '1'},{'LOWER':'disease'}]\n",
        "matcher = Matcher(nlp.vocab)\n",
        "matcher.add('disease', collect_sents, pattern)\n",
        "\n",
        "for doc in nlp.pipe(immune_df.head(1000), disable=['ner']): # enable parser to collect sents\n",
        "    matcher(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "id": "Fu7H5E9s8NTZ",
        "outputId": "460d5e4e-2034-47ee-dd4a-47d00e55ee28",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "defaultdict(int,\n",
              "            {'addison disease': 1,\n",
              "             'graves disease': 4,\n",
              "             'heart disease': 2,\n",
              "             'liver disease': 1,\n",
              "             'mouth disease': 1,\n",
              "             'thyroid disease': 1,\n",
              "             'whipple disease': 4})"
            ]
          },
          "execution_count": 106,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ent_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v48JVE_T8NTa"
      },
      "source": [
        "##### Multiple Patterns\n",
        "\n",
        "SpaCy matchers can use multiple patterns. Each pattern can be added to the Matcher individually with match.add and can use their own collect_sents function. Or use *patterns to add multiple patterns to the matcher at once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fcV3dcr8NTa"
      },
      "outputs": [],
      "source": [
        "matched_sents = []\n",
        "ent_sents  = defaultdict(list)\n",
        "ent_count = defaultdict(int)\n",
        "\n",
        "# multiple patterns\n",
        "pattern = [[{'POS': 'NOUN', 'OP': '+'},{'LOWER': 'disease'}]\n",
        "           , [{'POS': 'NOUN', 'OP': '+'},{'LOWER': 'disorder'}]]\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# *patterns to add multiple patterns with the same collect_sents function\n",
        "matcher.add('disease_disorder', collect_sents, *pattern)\n",
        "\n",
        "for doc in nlp.pipe(immune_df.head(500), disable=['ner']):\n",
        "    matches = matcher(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "id": "LnQ_v3bm8NTb",
        "outputId": "d237f124-01d0-41cb-e89f-964df4737c10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "defaultdict(int,\n",
              "            {'addison disease': 1,\n",
              "             'analogy graves disease': 1,\n",
              "             'graves disease': 2,\n",
              "             'heart disease': 2,\n",
              "             'hyperthyroidism graves disease': 1,\n",
              "             'liver disease': 1,\n",
              "             'thyroid disease': 1})"
            ]
          },
          "execution_count": 108,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ent_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUfibo2RD7i4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "-8lKVVLl8NRF"
      ],
      "name": "text_preprocessing_exercise.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
